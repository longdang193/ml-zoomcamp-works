{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 8 Homework: Hair Type Classification with CNN\n",
        "\n",
        "This homework focuses on building a Convolutional Neural Network (CNN) from scratch using PyTorch to classify hair types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Tools:\n",
        "- PyTorch 2.8.0\n",
        "- torchvision\n",
        "- PIL (Pillow)\n",
        "- NumPy\n",
        "- torchsummary (for model summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (if needed)\n",
        "# !pip install torch torchvision pillow numpy torchsummary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset\n",
        "\n",
        "In this homework, we'll build a model for classifying various hair types using the Hair Type dataset from [Kaggle](https://www.kaggle.com/datasets/kavyasreeb/hair-type-dataset).\n",
        "\n",
        "The dataset contains around 1000 images of hairs in separate folders for training and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already downloaded.\n",
            "Dataset already extracted.\n"
          ]
        }
      ],
      "source": [
        "# Dataset download URL\n",
        "DATASET_URL = 'https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip'\n",
        "DATASET_FILENAME = 'data.zip'\n",
        "\n",
        "# Download the dataset\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "if not os.path.exists(DATASET_FILENAME):\n",
        "    print(f\"Downloading dataset from {DATASET_URL}...\")\n",
        "    urllib.request.urlretrieve(DATASET_URL, DATASET_FILENAME)\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded.\")\n",
        "\n",
        "# Unzip the dataset\n",
        "if not os.path.exists('data'):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATASET_FILENAME, 'r') as zip_ref:\n",
        "        zip_ref.extractall('.')\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reproducibility\n",
        "\n",
        "Reproducibility in deep learning requires setting random number seed generators to ensure consistent results across runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seeds set to 42 for reproducibility\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Reproducibility constants\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "def set_random_seeds(seed=RANDOM_SEED):\n",
        "    \"\"\"\n",
        "    Sets random seeds for reproducibility across NumPy and PyTorch.\n",
        "    \n",
        "    Args:\n",
        "        seed (int): Random seed value. Default is 42.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    \n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_random_seeds(RANDOM_SEED)\n",
        "print(f\"Random seeds set to {RANDOM_SEED} for reproducibility\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n",
        "\n",
        "We'll build a Convolutional Neural Network (CNN) with the following structure:\n",
        "\n",
        "1. Input: `(3, 200, 200)` - RGB images (channels first format)\n",
        "2. Convolutional layer: 32 filters, kernel size (3, 3), ReLU activation\n",
        "3. Max pooling: Pool size (2, 2)\n",
        "4. Flatten: Convert multi-dimensional tensor to 1D vector using `torch.flatten`\n",
        "5. Dense layer: 64 neurons with ReLU activation\n",
        "6. Output layer: 1 neuron with sigmoid activation (for binary classification)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Model architecture constants\n",
        "INPUT_CHANNELS = 3\n",
        "INPUT_HEIGHT = 200\n",
        "INPUT_WIDTH = 200\n",
        "CONV_OUTPUT_CHANNELS = 32\n",
        "CONV_KERNEL_SIZE = 3\n",
        "CONV_PADDING = 0  # No padding\n",
        "CONV_STRIDE = 1  # Default stride\n",
        "POOL_SIZE = 2\n",
        "POOL_STRIDE = 2  # Default stride for pooling\n",
        "DENSE_NEURONS = 64\n",
        "OUTPUT_NEURONS = 1\n",
        "\n",
        "class HairTypeClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN model for binary hair type classification.\n",
        "    \n",
        "    Architecture:\n",
        "    - Conv2d: 32 filters, 3x3 kernel, ReLU\n",
        "    - MaxPool2d: 2x2 pooling\n",
        "    - Linear: 64 neurons, ReLU\n",
        "    - Linear: 1 neuron (logit output for binary classification)\n",
        "    \n",
        "    Args:\n",
        "        input_channels (int): Number of input channels. Default is 3 (RGB).\n",
        "        input_height (int): Input image height. Default is 200.\n",
        "        input_width (int): Input image width. Default is 200.\n",
        "        conv_output_channels (int): Number of output channels from conv layer. Default is 32.\n",
        "        conv_kernel_size (int): Size of convolutional kernel. Default is 3.\n",
        "        conv_padding (int): Padding for convolutional layer. Default is 0.\n",
        "        conv_stride (int): Stride for convolutional layer. Default is 1.\n",
        "        pool_size (int): Size of max pooling. Default is 2.\n",
        "        pool_stride (int): Stride for max pooling. Default is 2.\n",
        "        dense_neurons (int): Number of neurons in dense layer. Default is 64.\n",
        "        output_neurons (int): Number of output neurons. Default is 1.\n",
        "    \n",
        "    Returns:\n",
        "        torch.Tensor: Output logits of shape (batch_size, 1) for binary classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channels=INPUT_CHANNELS, input_height=INPUT_HEIGHT, \n",
        "                 input_width=INPUT_WIDTH, conv_output_channels=CONV_OUTPUT_CHANNELS,\n",
        "                 conv_kernel_size=CONV_KERNEL_SIZE, conv_padding=CONV_PADDING,\n",
        "                 conv_stride=CONV_STRIDE, pool_size=POOL_SIZE, pool_stride=POOL_STRIDE,\n",
        "                 dense_neurons=DENSE_NEURONS, output_neurons=OUTPUT_NEURONS):\n",
        "        super(HairTypeClassifier, self).__init__()\n",
        "        \n",
        "        # Convolutional layer (no padding)\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=input_channels,\n",
        "            out_channels=conv_output_channels,\n",
        "            kernel_size=conv_kernel_size,\n",
        "            padding=conv_padding,\n",
        "            stride=conv_stride\n",
        "        )\n",
        "        self.relu1 = nn.ReLU()\n",
        "        \n",
        "        # Max pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=pool_size, stride=pool_stride)\n",
        "        \n",
        "        # Calculate flattened size after conv and pooling\n",
        "        # Formula: output_size = (input_size + 2*padding - kernel_size) // stride + 1\n",
        "        # After conv (3x3, padding=0, stride=1): (200, 200) -> (198, 198)\n",
        "        # After pool (2x2, stride=2): (198, 198) -> (99, 99)\n",
        "        conv_output_height = (input_height + 2 * conv_padding - conv_kernel_size) // conv_stride + 1\n",
        "        conv_output_width = (input_width + 2 * conv_padding - conv_kernel_size) // conv_stride + 1\n",
        "        pooled_height = (conv_output_height - pool_size) // pool_stride + 1\n",
        "        pooled_width = (conv_output_width - pool_size) // pool_stride + 1\n",
        "        flattened_size = conv_output_channels * pooled_height * pooled_width\n",
        "        \n",
        "        # Dense layers\n",
        "        self.fc1 = nn.Linear(flattened_size, dense_neurons)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(dense_neurons, output_neurons)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "        \n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, 3, 200, 200).\n",
        "        \n",
        "        Returns:\n",
        "            torch.Tensor: Output logits of shape (batch_size, 1).\n",
        "        \"\"\"\n",
        "        # Convolutional block\n",
        "        x = self.conv(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # Flatten (start_dim=1 to keep batch dimension)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        \n",
        "        # Dense layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE:\n",
        "\n",
        "* **Convolution Output (Height/Width):** $$\\text{Output} = \\frac{\\text{Input} - \\text{Kernel} + 2 \\times \\text{Padding}}{\\text{Stride}} + 1$$\n",
        "\t*(Note: If $\\text{Padding} = 1$, Kernel = 3, and Stride = 1, Output Size equals Input Size.)*\n",
        "\n",
        "* **Max Pooling Output:** $$\\text{Output} = \\frac{\\text{Input}}{\\text{Pool Size}}$$\n",
        "\n",
        "* **Flattened Size:** $$\\text{Flat} = \\text{Channels} \\times \\text{Height} \\times \\text{Width}$$\n",
        "\n",
        "* **Dense Layer Output:** $$\\text{Output} = \\text{Input Vector Size} \\times \\text{Number of Neurons}$$\n",
        "\n",
        "* **Sigmoid Activation:** $$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Model created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create model instance\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = HairTypeClassifier()\n",
        "model.to(device)\n",
        "print(\"Model created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Architecture:\n",
            "HairTypeClassifier(\n",
            "  (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=313632, out_features=64, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Display model architecture\n",
        "print(\"Model Architecture:\")\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 198, 198]             896\n",
            "              ReLU-2         [-1, 32, 198, 198]               0\n",
            "         MaxPool2d-3           [-1, 32, 99, 99]               0\n",
            "            Linear-4                   [-1, 64]      20,072,512\n",
            "              ReLU-5                   [-1, 64]               0\n",
            "            Linear-6                    [-1, 1]              65\n",
            "================================================================\n",
            "Total params: 20,073,473\n",
            "Trainable params: 20,073,473\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 21.54\n",
            "Params size (MB): 76.57\n",
            "Estimated Total Size (MB): 98.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Using torchsummary for detailed model summary\n",
        "try:\n",
        "    from torchsummary import summary\n",
        "    summary(model, input_size=(INPUT_CHANNELS, INPUT_HEIGHT, INPUT_WIDTH))\n",
        "except ImportError:\n",
        "    print(\"torchsummary not installed. Install with: pip install torchsummary\")\n",
        "    print(\"Using manual parameter count instead.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizer: SGD with lr=0.002, momentum=0.8\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Optimizer hyperparameters\n",
        "LEARNING_RATE = 0.002\n",
        "MOMENTUM = 0.8\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "print(f\"Optimizer: SGD with lr={LEARNING_RATE}, momentum={MOMENTUM}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss function: BCEWithLogitsLoss (logits + sigmoid internally)\n"
          ]
        }
      ],
      "source": [
        "# Loss function for binary classification\n",
        "# Use BCEWithLogitsLoss to combine a stable sigmoid + BCE in one op\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "print(\"Loss function: BCEWithLogitsLoss (logits + sigmoid internally)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contents of current directory:\n",
            "['.config', 'data.zip', 'data', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Contents of current directory:\")\n",
        "print(os.listdir('.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Contents of data folder:\n",
            "['test', 'train']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nContents of data folder:\")\n",
        "if os.path.exists('data'):\n",
        "    print(os.listdir('data'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "class HairTypeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for loading hair type images from directory structure.\n",
        "    \n",
        "    Args:\n",
        "        data_dir (str): Path to root directory containing class subdirectories.\n",
        "        transform (callable, optional): Transform pipeline to apply to images.\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (transformed_image, label) when indexed.\n",
        "    \n",
        "    Raises:\n",
        "        FileNotFoundError: If data_dir does not exist.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(data_dir))\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_directory = os.path.join(data_dir, class_name)\n",
        "            for image_filename in os.listdir(class_directory):\n",
        "                image_path = os.path.join(class_directory, image_filename)\n",
        "                self.image_paths.append(image_path)\n",
        "                self.labels.append(self.class_to_idx[class_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image preprocessing constants\n",
        "IMAGE_SIZE = 200\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def create_transforms(image_size=IMAGE_SIZE):\n",
        "    \"\"\"\n",
        "    Creates transform pipeline for image preprocessing.\n",
        "    \n",
        "    Args:\n",
        "        image_size (int): Target size for resizing. Default is 200.\n",
        "    \n",
        "    Returns:\n",
        "        transforms.Compose: Transform pipeline with resize, ToTensor, and normalization.\n",
        "    \"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "    ])\n",
        "\n",
        "# Create transforms for train and test\n",
        "train_transforms = create_transforms(IMAGE_SIZE)\n",
        "test_transforms = create_transforms(IMAGE_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 801\n",
            "Test samples: 201\n",
            "Number of classes: 2\n",
            "Classes: ['curly', 'straight']\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Dataset paths\n",
        "TRAIN_DATA_DIR = './data/train'\n",
        "TEST_DATA_DIR = './data/test'\n",
        "\n",
        "# DataLoader hyperparameters\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_TRAIN = True\n",
        "SHUFFLE_TEST = False\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = HairTypeDataset(\n",
        "    data_dir=TRAIN_DATA_DIR,\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = HairTypeDataset(\n",
        "    data_dir=TEST_DATA_DIR,\n",
        "    transform=test_transforms\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=SHUFFLE_TRAIN\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=SHUFFLE_TEST\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Classes: {train_dataset.classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training constants\n",
        "SIGMOID_THRESHOLD = 0.5\n",
        "LABEL_UNSQUEEZE_DIM = 1\n",
        "\n",
        "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Trains the model for one epoch.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model to train.\n",
        "        train_loader: DataLoader for training data.\n",
        "        optimizer: Optimizer for updating model parameters.\n",
        "        criterion: Loss function.\n",
        "        device: Device to run training on (cuda/cpu).\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) for the epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Ensure labels are float and have shape (batch_size, 1)\n",
        "        labels = labels.float().unsqueeze(LABEL_UNSQUEEZE_DIM)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # Apply sigmoid and threshold for binary classification\n",
        "        predicted = (torch.sigmoid(outputs) > SIGMOID_THRESHOLD).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    average_loss = running_loss / len(train_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return average_loss, accuracy\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluates the model on data.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model to evaluate.\n",
        "        data_loader: DataLoader for evaluation data.\n",
        "        criterion: Loss function.\n",
        "        device: Device to run evaluation on (cuda/cpu).\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy) for the dataset.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # Convert labels to float and add dimension for binary classification\n",
        "            labels = labels.float().unsqueeze(LABEL_UNSQUEEZE_DIM)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            # Apply sigmoid and threshold for binary classification\n",
        "            predicted = (torch.sigmoid(outputs) > SIGMOID_THRESHOLD).float()\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    average_loss = running_loss / len(data_loader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return average_loss, accuracy\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device, history=None):\n",
        "    \"\"\"\n",
        "    Trains and evaluates a model for multiple epochs.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model to train.\n",
        "        optimizer: Optimizer for updating model parameters.\n",
        "        train_loader: DataLoader for training data.\n",
        "        val_loader: DataLoader for validation/test data.\n",
        "        criterion: Loss function.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        device: Device to run training on (cuda/cpu).\n",
        "        history (dict, optional): Dictionary to store training history. If None, creates new one.\n",
        "    \n",
        "    Returns:\n",
        "        dict: Training history with 'acc', 'loss', 'val_acc', 'val_loss' keys.\n",
        "    \"\"\"\n",
        "    if history is None:\n",
        "        history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc = evaluate_model(\n",
        "            model, val_loader, criterion, device)\n",
        "\n",
        "        # Store history\n",
        "        history['loss'].append(train_loss)\n",
        "        history['acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.6230, Acc: 0.6554, Val Loss: 0.7524, Val Acc: 0.6070\n",
            "Epoch 2/10, Loss: 0.5648, Acc: 0.6879, Val Loss: 0.6136, Val Acc: 0.6567\n",
            "Epoch 3/10, Loss: 0.5274, Acc: 0.7366, Val Loss: 0.6602, Val Acc: 0.6418\n",
            "Epoch 4/10, Loss: 0.4862, Acc: 0.7478, Val Loss: 0.6801, Val Acc: 0.6169\n",
            "Epoch 5/10, Loss: 0.4317, Acc: 0.8027, Val Loss: 0.6286, Val Acc: 0.6567\n",
            "Epoch 6/10, Loss: 0.4073, Acc: 0.7990, Val Loss: 0.9441, Val Acc: 0.5871\n",
            "Epoch 7/10, Loss: 0.5136, Acc: 0.7528, Val Loss: 0.6664, Val Acc: 0.6318\n",
            "Epoch 8/10, Loss: 0.3495, Acc: 0.8702, Val Loss: 0.6588, Val Acc: 0.6866\n",
            "Epoch 9/10, Loss: 0.2745, Acc: 0.8814, Val Loss: 2.2306, Val Acc: 0.5323\n",
            "Epoch 10/10, Loss: 0.7116, Acc: 0.6891, Val Loss: 0.6192, Val Acc: 0.6716\n",
            "\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Training hyperparameters\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Train and evaluate the model\n",
        "history = train_and_evaluate(\n",
        "    model, optimizer, train_loader, test_loader, \n",
        "    criterion, NUM_EPOCHS, device\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.7503121098626717)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Question 3: Median of training accuracy\n",
        "train_acc_median = np.median(history['acc'])\n",
        "train_acc_median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.12278403513656203)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 4: Standard deviation of training loss\n",
        "train_loss_std = np.std(history['loss'])\n",
        "train_loss_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Augmentation\n",
        "\n",
        "For the next two questions, we will train the same model for 10 additional epochs using data augmentation **only on the training data**. We will use the following augmentations, as specified in the homework:\n",
        "\n",
        "- `transforms.RandomRotation(50)`\n",
        "- `transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1))`\n",
        "- `transforms.RandomHorizontalFlip()`\n",
        "\n",
        "The test set will continue to use only resizing, tensor conversion, and normalization (no augmentation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset with augmentation created.\n",
            "Training samples: 801\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation hyperparameters\n",
        "MAX_ROTATION_DEGREES = 50\n",
        "RANDOM_CROP_SCALE = (0.9, 1.0)\n",
        "RANDOM_CROP_RATIO = (0.9, 1.1)\n",
        "\n",
        "\n",
        "def create_augmented_transforms(image_size=IMAGE_SIZE):\n",
        "    \"\"\"Create transform pipeline for image preprocessing with data augmentation.\n",
        "\n",
        "    Args:\n",
        "        image_size (int): Target size for resized/cropped images. Default is IMAGE_SIZE.\n",
        "\n",
        "    Returns:\n",
        "        transforms.Compose: Transform pipeline with rotation, random crop,\n",
        "            horizontal flip, tensor conversion, and normalization.\n",
        "    \"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.RandomRotation(MAX_ROTATION_DEGREES),\n",
        "        transforms.RandomResizedCrop(\n",
        "            image_size,\n",
        "            scale=RANDOM_CROP_SCALE,\n",
        "            ratio=RANDOM_CROP_RATIO,\n",
        "        ),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "    ])\n",
        "\n",
        "\n",
        "# Replace training transforms with augmented version (test transforms stay the same)\n",
        "train_transforms_augmented = create_augmented_transforms(IMAGE_SIZE)\n",
        "\n",
        "train_dataset = HairTypeDataset(\n",
        "    data_dir=TRAIN_DATA_DIR,\n",
        "    transform=train_transforms_augmented,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=SHUFFLE_TRAIN,\n",
        ")\n",
        "\n",
        "print(\"Training dataset with augmentation created.\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.6007, Acc: 0.6779, Val Loss: 0.6151, Val Acc: 0.6915\n",
            "Epoch 2/10, Loss: 0.5683, Acc: 0.6754, Val Loss: 0.6007, Val Acc: 0.6915\n",
            "Epoch 3/10, Loss: 0.5387, Acc: 0.7004, Val Loss: 0.7636, Val Acc: 0.6119\n",
            "Epoch 4/10, Loss: 0.5489, Acc: 0.7079, Val Loss: 0.6943, Val Acc: 0.6716\n",
            "Epoch 5/10, Loss: 0.5360, Acc: 0.7241, Val Loss: 0.5984, Val Acc: 0.7164\n",
            "Epoch 6/10, Loss: 0.5356, Acc: 0.7191, Val Loss: 0.6415, Val Acc: 0.6716\n",
            "Epoch 7/10, Loss: 0.5069, Acc: 0.7391, Val Loss: 0.7381, Val Acc: 0.6169\n",
            "Epoch 8/10, Loss: 0.5385, Acc: 0.7191, Val Loss: 0.7462, Val Acc: 0.6318\n",
            "Epoch 9/10, Loss: 0.4950, Acc: 0.7566, Val Loss: 0.6101, Val Acc: 0.6866\n",
            "Epoch 10/10, Loss: 0.4933, Acc: 0.7516, Val Loss: 0.5665, Val Acc: 0.7164\n",
            "\n",
            "Augmented training completed!\n"
          ]
        }
      ],
      "source": [
        "# Continue training with data augmentation (10 more epochs)\n",
        "NUM_EPOCHS_AUGMENTED = 10\n",
        "\n",
        "aug_history = train_and_evaluate(\n",
        "    model,\n",
        "    optimizer,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    NUM_EPOCHS_AUGMENTED,\n",
        "    device,\n",
        ")\n",
        "\n",
        "print(\"\\nAugmented training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6574376635364632)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 5: Mean of test loss (validation loss) for augmented training epochs\n",
        "augmented_test_loss_mean = np.mean(aug_history['val_loss'])\n",
        "augmented_test_loss_mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6646766169154229)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 6: Average test accuracy for the last 5 augmented epochs (6 to 10)\n",
        "LAST_EPOCHS_START_INDEX = 5  # zero-based index corresponding to epoch 6\n",
        "\n",
        "test_accuracy_last_five_mean = np.mean(aug_history['val_acc'][LAST_EPOCHS_START_INDEX:])\n",
        "test_accuracy_last_five_mean\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
