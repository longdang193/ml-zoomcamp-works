{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 9 Homework: Serverless Deployment\n",
        "\n",
        "This homework focuses on deploying the Straight vs Curly Hair Type model (trained in Week 8) as a serverless function using ONNX, Docker, and AWS Lambda.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Tools:\n",
        "- ONNX Runtime\n",
        "- PIL (Pillow)\n",
        "- NumPy\n",
        "- Docker (for later questions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# # Install required packages (if needed)\n",
        "!pip install onnxruntime pillow numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Download\n",
        "\n",
        "Download the ONNX model files from the repository. These files contain the pre-trained hair type classifier model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists: hair_classifier_v1.onnx.data\n",
            "File already exists: hair_classifier_v1.onnx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Model download URLs\n",
        "MODEL_PREFIX = \"https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle\"\n",
        "MODEL_DATA_URL = f\"{MODEL_PREFIX}/hair_classifier_v1.onnx.data\"\n",
        "MODEL_URL = f\"{MODEL_PREFIX}/hair_classifier_v1.onnx\"\n",
        "\n",
        "# Local filenames\n",
        "MODEL_DATA_FILENAME = \"hair_classifier_v1.onnx.data\"\n",
        "MODEL_FILENAME = \"hair_classifier_v1.onnx\"\n",
        "\n",
        "\n",
        "def download_file(url, filename):\n",
        "    \"\"\"Download a file from URL if it doesn't already exist.\n",
        "\n",
        "    Args:\n",
        "        url (str): URL to download from.\n",
        "        filename (str): Local filename to save to.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Downloading {filename} from {url}...\")\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "        print(f\"Download complete: {filename}\")\n",
        "    else:\n",
        "        print(f\"File already exists: {filename}\")\n",
        "\n",
        "\n",
        "# Download model files\n",
        "download_file(MODEL_DATA_URL, MODEL_DATA_FILENAME)\n",
        "download_file(MODEL_URL, MODEL_FILENAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1: Input and Output Node Names\n",
        "\n",
        "To use the ONNX model, we need to know the names of the input and output nodes. Let's inspect the model to find these names.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Structure Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            "  input: ['?', 3, 200, 200]\n",
            "\n",
            "Outputs:\n",
            "  output: ['?', 1]\n",
            "\n",
            "Output node name: output\n"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(MODEL_FILENAME)\n",
        "graph = onnx_model.graph\n",
        "\n",
        "# Input and output information\n",
        "print(\"Inputs:\")\n",
        "for inp in graph.input:\n",
        "    shape = [dim.dim_value if dim.dim_value > 0 else '?' \n",
        "             for dim in inp.type.tensor_type.shape.dim]\n",
        "    print(f\"  {inp.name}: {shape}\")\n",
        "\n",
        "print(\"\\nOutputs:\")\n",
        "for out in graph.output:\n",
        "    shape = [dim.dim_value if dim.dim_value > 0 else '?' \n",
        "             for dim in out.type.tensor_type.shape.dim]\n",
        "    print(f\"  {out.name}: {shape}\")\n",
        "\n",
        "# Store output name\n",
        "OUTPUT_NODE_NAME = graph.output[0].name\n",
        "print(f\"\\nOutput node name: {OUTPUT_NODE_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total layers: 9\n",
            "\n",
            "  1. Shape                | input -> val_0\n",
            "  2. Conv                 | input, conv1.weight, conv1.bias -> conv2d\n",
            "  3. Relu                 | conv2d -> relu\n",
            "  4. MaxPool              | relu -> max_pool2d\n",
            "  5. Concat               | val_0, val_4 -> val_5\n",
            "  6. Reshape              | max_pool2d, val_5 -> view\n",
            "  7. Gemm                 | view, fc1.weight, fc1.bias -> linear\n",
            "  8. Relu                 | linear -> relu_1\n",
            "  9. Gemm                 | relu_1, fc2.weight, fc2.bias -> output\n"
          ]
        }
      ],
      "source": [
        "# Display model layers (nodes)\n",
        "print(f\"Total layers: {len(graph.node)}\\n\")\n",
        "\n",
        "for i, node in enumerate(graph.node, 1):\n",
        "    inputs = ', '.join(node.input) if node.input else 'N/A'\n",
        "    outputs = ', '.join(node.output) if node.output else 'N/A'\n",
        "    print(f\"{i:3d}. {node.op_type:20s} | {inputs} -> {outputs}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2: Target Size\n",
        "\n",
        "Download and resize the test image to the target size used in Week 8 preprocessing (200×200).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from urllib import request\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_URL = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
        "TARGET_SIZE = (200, 200)  # from Week 8 preprocessing\n",
        "\n",
        "\n",
        "def download_image(url: str) -> Image.Image:\n",
        "    \"\"\"Download an image from a URL into a PIL RGB image.\"\"\"\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    return Image.open(BytesIO(buffer)).convert(\"RGB\")\n",
        "\n",
        "\n",
        "def prepare_image(img: Image.Image, target_size=TARGET_SIZE) -> Image.Image:\n",
        "    \"\"\"Convert to RGB and resize to the given target size.\"\"\"\n",
        "    if img.mode != \"RGB\":\n",
        "        img = img.convert(\"RGB\")\n",
        "    return img.resize(target_size, Image.NEAREST)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original size: (1024, 1024)\n",
            "Resized size:  (200, 200)\n"
          ]
        }
      ],
      "source": [
        "# Download and resize\n",
        "test_img = download_image(IMAGE_URL)\n",
        "resized_img = prepare_image(test_img, TARGET_SIZE)\n",
        "\n",
        "print(f\"Original size: {test_img.size}\")\n",
        "print(f\"Resized size:  {resized_img.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PIL.Image.Image"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(resized_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Array shape: (200, 200, 3)\n",
            "First pixel (R, G, B): [61, 104, 22]\n"
          ]
        }
      ],
      "source": [
        "# Convert resized image to NumPy array for the next steps\n",
        "img_array = np.array(resized_img)\n",
        "print(f\"Array shape: {img_array.shape}\")\n",
        "print(f\"First pixel (R, G, B): {img_array[0, 0, :].tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3: Preprocess and First-Pixel Value (R channel)\n",
        "\n",
        "Apply the same preprocessing as in Week 8 (ToTensor + ImageNet normalization) and report the first pixel's R value after normalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed tensor shape (C,H,W): (3, 200, 200)\n",
            "First pixel R channel after normalization: -1.0732940435409546\n"
          ]
        }
      ],
      "source": [
        "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "\n",
        "def preprocess_to_tensor(img_array: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Convert HWC uint8 image to CHW float32 tensor and apply ImageNet normalization.\"\"\"\n",
        "    # ToTensor: scale to [0,1] and reorder to CHW\n",
        "    tensor = img_array.astype(np.float32) / 255.0\n",
        "    tensor = np.transpose(tensor, (2, 0, 1))  # HWC -> CHW\n",
        "    # Normalize per channel\n",
        "    tensor = (tensor - IMAGENET_MEAN[:, None, None]) / IMAGENET_STD[:, None, None]\n",
        "    return tensor\n",
        "\n",
        "\n",
        "# Preprocess and extract first-pixel R value\n",
        "preprocessed = preprocess_to_tensor(img_array)\n",
        "first_pixel_r = float(preprocessed[0, 0, 0])\n",
        "\n",
        "print(f\"Preprocessed tensor shape (C,H,W): {preprocessed.shape}\")\n",
        "print(f\"First pixel R channel after normalization: {first_pixel_r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4: Run the Model on the Image\n",
        "\n",
        "Run inference with ONNX Runtime on the preprocessed tensor and report the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import onnxruntime as ort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output (logit): 0.09156641364097595\n"
          ]
        }
      ],
      "source": [
        "# Prepare batch dimension (N, C, H, W)\n",
        "input_tensor = np.expand_dims(preprocessed, axis=0)\n",
        "\n",
        "# Load model and run inference\n",
        "session = ort.InferenceSession(MODEL_FILENAME)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output = session.run(None, {input_name: input_tensor})\n",
        "\n",
        "# Extract scalar prediction\n",
        "model_output = float(output[0].squeeze())\n",
        "print(f\"Model output (logit): {model_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 5: Base Image Size\n",
        "\n",
        "Pull the base image `agrigorev/model-2025-hairstyle:v1` and check its size (in the SIZE column of `docker images`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPOSITORY                       TAG       IMAGE ID       CREATED      SIZE\n",
            "agrigorev/model-2025-hairstyle   v1        9e43d5a5323f   6 days ago   921MB\n"
          ]
        }
      ],
      "source": [
        "# Pull the base image and list its size\n",
        "!docker pull agrigorev/model-2025-hairstyle:v1\n",
        "!docker images agrigorev/model-2025-hairstyle:v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 6: Extend the Image, Add Lambda Code, and Score the Image\n",
        "\n",
        "The base image `agrigorev/model-2025-hairstyle:v1` already contains `hair_classifier_empty.onnx` (same preprocessing as Week 8). Steps:\n",
        "1. Extend the base image, install required libs, and add the lambda handler code.\n",
        "2. Run the container locally.\n",
        "3. Score the provided image and report the model output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dockerfile (homework.dockerfile)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing homework.dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile homework.dockerfile\n",
        "FROM agrigorev/model-2025-hairstyle:v1\n",
        "\n",
        "# Install Python deps needed for the lambda handler\n",
        "RUN pip install --no-cache-dir pillow numpy onnxruntime\n",
        "\n",
        "# Copy lambda handler into the image\n",
        "COPY lambda_function.py /var/task/lambda_function.py\n",
        "\n",
        "# Entrypoint is defined by the base Lambda image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create lambda_function.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing lambda_function.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile lambda_function.py\n",
        "import json\n",
        "from io import BytesIO\n",
        "from urllib import request\n",
        "\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "\n",
        "MODEL_PATH = \"hair_classifier_empty.onnx\"\n",
        "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "TARGET_SIZE = (200, 200)\n",
        "\n",
        "\n",
        "def download_image(url: str) -> Image.Image:\n",
        "    \"\"\"Download an image from URL and ensure RGB mode.\"\"\"\n",
        "    with request.urlopen(url) as resp:\n",
        "        buffer = resp.read()\n",
        "    return Image.open(BytesIO(buffer)).convert(\"RGB\")\n",
        "\n",
        "\n",
        "def prepare_image(img: Image.Image, target_size=TARGET_SIZE) -> np.ndarray:\n",
        "    \"\"\"Resize, normalize (ImageNet), and return NCHW float32 tensor with batch dim.\"\"\"\n",
        "    img = img.resize(target_size, Image.NEAREST)\n",
        "    arr = np.array(img).astype(np.float32) / 255.0  # HWC, [0,1]\n",
        "    arr = np.transpose(arr, (2, 0, 1))               # CHW\n",
        "    arr = (arr - IMAGENET_MEAN[:, None, None]) / IMAGENET_STD[:, None, None]\n",
        "    return np.expand_dims(arr, axis=0)               # NCHW\n",
        "\n",
        "\n",
        "def predict(url: str) -> float:\n",
        "    session = ort.InferenceSession(MODEL_PATH, providers=[\"CPUExecutionProvider\"])\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    img = download_image(url)\n",
        "    tensor = prepare_image(img)\n",
        "    output = session.run(None, {input_name: tensor})[0]\n",
        "    return float(output.squeeze())\n",
        "\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    url = event.get(\"url\") if isinstance(event, dict) else None\n",
        "    if not url:\n",
        "        return {\n",
        "            \"statusCode\": 400,\n",
        "            \"body\": json.dumps({\"error\": \"url is required\"}),\n",
        "        }\n",
        "    pred = predict(url)\n",
        "    return {\n",
        "        \"statusCode\": 200,\n",
        "        \"body\": json.dumps({\"prediction\": pred}),\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build and Run Locally\n",
        "\n",
        "```bash\n",
        "# Build the image\n",
        "docker build -t hairstyle-lambda -f homework.dockerfile .\n",
        "\n",
        "# Run the container locally\n",
        "docker run --rm -p 9000:8080 hairstyle-lambda lambda_function.lambda_handler\n",
        "\n",
        "# Invoke (Lambda format)\n",
        "curl -X POST \"http://localhost:9000/2015-03-31/functions/function/invocations\" \\\n",
        "     -d '{\"url\": \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"}'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE: When a Lambda container runs locally with the **AWS Lambda Runtime Interface Emulator (RIE)**, it exposes a fixed HTTP endpoint that mimics the real Lambda Invoke API.\n",
        "Because of this, every local invocation uses the same request pattern:\n",
        "\n",
        "* **URL:** `http://localhost:9000/2015-03-31/functions/function/invocations`\n",
        "* **Method:** `POST`\n",
        "* **Body:** The JSON event you want to pass to the handler\n",
        "\n",
        "This endpoint is not configurable—it exists to replicate how AWS Lambda receives events.\n",
        "Posting your JSON payload to this path triggers the handler inside the container exactly as Lambda would in the cloud.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
